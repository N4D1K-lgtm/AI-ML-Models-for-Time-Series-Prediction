{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MultivariateLSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python39764bittfcondad42380e37f19495997ad366e61cbaf70",
      "display_name": "Python 3.9.7 64-bit ('tf': conda)"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.7-final"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# !pip install tensorflow-gpu # make sure cuda toolkit and nvidia dependencies/drivers are correctly installed\n",
        "# !pip install pandas\n",
        "# !pip install numpy\n",
        "# !pip install matplotlib\n",
        "# !pip install mlflow\n",
        "# !pip install scipy\n",
        "# !pip install keras"
      ],
      "metadata": {
        "id": "INLDzE7ASC3Q"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Sf50m6aMRR81"
      },
      "outputs": [],
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.models import Model\n",
        "\n",
        "\n",
        "from keras.layers import Input, LSTM, Bidirectional, Dense, Masking, Reshape, Activation, Masking\n",
        "from keras.layers import Conv1D, BatchNormalization, GlobalAveragePooling1D, Permute, Dropout, concatenate\n",
        "\n",
        "from keras.preprocessing.sequence import TimeseriesGenerator\n",
        "from keras.callbacks import TensorBoard, EarlyStopping\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from time import time\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "from ProcessData import get_vol, get_touches, get_labels, get_horizons, load_data, label_series\n",
        "from ModelArchitecture import generate_mlstmfcn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n",
            "2022-03-02 16:58:34.442379: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-03-02 16:58:34.840507: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /device:GPU:0 with 4177 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
          ]
        }
      ],
      "source": [
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_df, names = load_data(\"../Data/\")"
      ],
      "metadata": {
        "id": "WE-vs10WToFk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatetimeIndex(['2020-01-16 00:00:00', '2020-01-16 00:05:00',\n               '2020-01-16 00:10:00', '2020-01-16 00:15:00',\n               '2020-01-16 00:20:00', '2020-01-16 00:25:00',\n               '2020-01-16 00:30:00', '2020-01-16 00:35:00',\n               '2020-01-16 00:40:00', '2020-01-16 00:45:00',\n               ...\n               '2022-01-15 10:05:00', '2022-01-15 10:10:00',\n               '2022-01-15 10:15:00', '2022-01-15 10:20:00',\n               '2022-01-15 10:25:00', '2022-01-15 10:30:00',\n               '2022-01-15 10:35:00', '2022-01-15 10:40:00',\n               '2022-01-15 10:45:00', '2022-01-15 10:50:00'],\n              dtype='datetime64[ns]', name='Timestamp', length=209972, freq=None)\n"
          ]
        }
      ],
      "source": [
        "BTC_SAMPLE = pd.DataFrame(index = dataset_df.index)\n",
        "BTC_SAMPLE[\"Close\"] = dataset_df['BTC_USD-5m']\n",
        "print(BTC_SAMPLE.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "labels = label_series(BTC_SAMPLE.Close)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatetimeIndex(['2020-01-16 01:10:00', '2020-01-16 01:15:00',\n               '2020-01-16 01:20:00', '2020-01-16 01:25:00',\n               '2020-01-16 01:30:00', '2020-01-16 01:35:00',\n               '2020-01-16 01:40:00', '2020-01-16 01:45:00',\n               '2020-01-16 01:50:00', '2020-01-16 01:55:00',\n               ...\n               '2022-01-15 09:50:00', '2022-01-15 09:55:00',\n               '2022-01-15 10:00:00', '2022-01-15 10:05:00',\n               '2022-01-15 10:10:00', '2022-01-15 10:15:00',\n               '2022-01-15 10:20:00', '2022-01-15 10:25:00',\n               '2022-01-15 10:30:00', '2022-01-15 10:35:00'],\n              dtype='datetime64[ns]', name='Timestamp', length=209955, freq=None)\n"
          ]
        }
      ],
      "source": [
        "print(labels.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "labels.to_csv('./Processed/BTClabels.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# labels = pd.read_csv('./Processed/BTClabels.csv')\n",
        "# labels.set_index('Timestamp', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                       Close\nTimestamp                   \n2020-01-16 00:00:00  8845.70\n2020-01-16 00:05:00  8844.44\n2020-01-16 00:10:00  8824.01\n2020-01-16 00:15:00  8812.22\n2020-01-16 00:20:00  8754.02\n(209972, 1)\nPrice Index 0: 2020-01-16 00:00:00 vs. Label Index 0: 2020-01-16 01:10:00\nPrice Index -1: 2022-01-15 10:50:00 vs. Price Index -1: 2022-01-15 10:35:00\n"
          ]
        }
      ],
      "source": [
        "print(BTC_SAMPLE.head(5))\n",
        "print(BTC_SAMPLE.shape)\n",
        "print(\"Price Index 0: {a} vs. Label Index 0: {b}\".format(a=BTC_SAMPLE.index[0], b=labels.index[0]))\n",
        "print(\"Price Index -1: {a} vs. Price Index -1: {b}\".format(a=BTC_SAMPLE.index[-1], b=labels.index[-1]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 0.0    0.566407\n 1.0    0.217828\n-1.0    0.215765\nName: label, dtype: float64\n(209955, 3)\n"
          ]
        }
      ],
      "source": [
        "BTC_SAMPLE = BTC_SAMPLE.truncate(before=pd.Timestamp(labels.index[0]), \\\n",
        "    after=pd.Timestamp(labels.index[-1]))\n",
        "labels = labels.truncate(before=pd.Timestamp(BTC_SAMPLE.index[0]), \\\n",
        "     after=pd.Timestamp(BTC_SAMPLE.index[-1]))\n",
        "\n",
        "np_labels = labels.to_numpy()\n",
        "one_hot_encoded_labels = to_categorical(np_labels, num_classes=3)\n",
        "print(labels.value_counts(normalize=True, dropna=True))\n",
        "print(one_hot_encoded_labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "values = BTC_SAMPLE.Close.to_numpy()\n",
        "print(values.shape)\n",
        "if values.ndim == 1:\n",
        "    values = values.reshape(-1, 1)\n",
        "scaler = MinMaxScaler()\n",
        "scaled = scaler.fit_transform(values)\n",
        "X = scaled\n",
        "\n",
        "\n",
        "input_timesteps = 128\n",
        "batch_size = 128\n",
        "\n",
        "# split into train and test sets (Train: 68%, Val: 12%, Test: 20%)\n",
        "trainX, testX, trainY, testY = train_test_split(X, one_hot_encoded_labels, test_size=0.20, random_state=42, shuffle = False)\n",
        "trainX, valX, trainY, valY = train_test_split(trainX, trainY, test_size=0.15, random_state=42, shuffle=False)\n",
        "\n",
        "train_generator = TimeseriesGenerator(trainX, trainY, length=input_timesteps, sampling_rate=1, batch_size=batch_size)\n",
        "val_generator = TimeseriesGenerator(valX, valY, length=input_timesteps, sampling_rate=1, batch_size=batch_size)\n",
        "test_generator = TimeseriesGenerator(testX, testY, length=input_timesteps, sampling_rate=1, batch_size=batch_size)\n",
        "\n",
        "train_sample_X, train_sample_y = train_generator[0]\n",
        "test_sample_X, test_sample_y = train_generator[0]\n",
        "\n",
        "print(\"TrainX Shape:\" + str(trainX.shape))\n",
        "print(\"TrainY Shape:\" + str(trainY.shape))\n",
        "print(\"TestX Shape:\" + str(testX.shape))\n",
        "print(\"TestY Shape:\" + str(testY.shape))\n",
        "print(\"Slice of Features from Train Generator:\" + str(train_sample_X.shape))\n",
        "print(\"Slice of Labels from Train Generator:\" + str(train_sample_y.shape))\n",
        "print(\"Slice of Features from Test Generator:\" + str(test_sample_X.shape))\n",
        "print(\"Slice of Labels from Test Generator:\" + str(test_sample_y.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqzU_NFganNz",
        "outputId": "a73349e2-5222-494f-b4b6-0a4a9aa4747d"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(209955,)\nTrainX Shape:(142769, 1)\nTrainY Shape:(142769, 3)\nTestX Shape:(41991, 1)\nTestY Shape:(41991, 3)\nSlice of Features from Train Generator:(128, 128, 1)\nSlice of Labels from Train Generator:(128, 3)\nSlice of Features from Test Generator:(128, 128, 1)\nSlice of Labels from Test Generator:(128, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_mlstmfcn(max_timesteps, max_features, classes, cells=8):\n",
        "    # MLSTM-FCN\n",
        "    # Multivariate Long-Short-Term Memory  \n",
        "    ip = Input(shape=(max_timesteps, max_features))\n",
        "\n",
        "    x = Masking()(ip)\n",
        "    x = LSTM(cells)(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "\n",
        "    # y = Permute((2, 1))(ip)\n",
        "    y = Conv1D(128, 8, padding='same', kernel_initializer='he_uniform')(ip)\n",
        "    y = BatchNormalization()(y)\n",
        "    y = Activation('relu')(y)\n",
        "    # y = squeeze_excite_block(y)\n",
        "\n",
        "    y = Conv1D(256, 5, padding='same', kernel_initializer='he_uniform')(y)\n",
        "    y = BatchNormalization()(y)\n",
        "    y = Activation('relu')(y)\n",
        "    # y = squeeze_excite_block(y)\n",
        "\n",
        "    y = Conv1D(128, 3, padding='same', kernel_initializer='he_uniform')(y)\n",
        "    y = BatchNormalization()(y)\n",
        "    y = Activation('relu')(y)\n",
        "\n",
        "    y = GlobalAveragePooling1D()(y)\n",
        "\n",
        "    x = concatenate([x, y])\n",
        "\n",
        "    out = Dense(classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(ip, out)\n",
        "    model.summary()\n",
        "\n",
        "    # add load model code here to fine-tune\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "units = 128 # Arbituary Number\n",
        "features = trainX.shape[1] # Number of different trading pairs in the dataframe ie. BTC/USD (aka: # of columns)\n",
        "num_epoch = 25\n",
        "learning_rate = 0.00144\n",
        "\n",
        "logdir = \"logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = TensorBoard(log_dir=logdir, histogram_freq=1)\n",
        "\n",
        "# input_shape=(train_sample_X[1].shape, train_sample_X[2].shape)\n",
        "model = generate_mlstmfcn(input_timesteps, features, 3, 64)\n",
        "\n",
        "\n",
        "\n",
        "adam = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "# Stop training when a monitored quantity has stopped improving.\n",
        "callbacks = [EarlyStopping(monitor=\"loss\", \\\n",
        "                            min_delta = 0.00001, \\\n",
        "                            patience = 50, mode = 'auto', \\\n",
        "                            restore_best_weights=True), \\\n",
        "                            tensorboard_callback] \n",
        "\n",
        "# Using regression loss function 'Mean Standard Error' and validation metric 'Mean Absolute Error'\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# fit network\n",
        "history = model.fit(train_generator, \\\n",
        "                            epochs=num_epoch, \\\n",
        "                            validation_data=val_generator, \\\n",
        "                            callbacks = callbacks, \\\n",
        "                            verbose=2, \\\n",
        "                            shuffle=False, \\\n",
        "                            initial_epoch=0)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kEJgb3UIiE36",
        "outputId": "1749a0a4-c9ab-487e-c98a-89457ef4c255"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_4 (InputLayer)           [(None, 128, 1)]     0           []                               \n",
            "                                                                                                  \n",
            " conv1d_9 (Conv1D)              (None, 128, 128)     1152        ['input_4[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 128, 128)    512         ['conv1d_9[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 128, 128)     0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " conv1d_10 (Conv1D)             (None, 128, 256)     164096      ['activation_9[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 128, 256)    1024        ['conv1d_10[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 128, 256)     0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " conv1d_11 (Conv1D)             (None, 128, 128)     98432       ['activation_10[0][0]']          \n",
            "                                                                                                  \n",
            " masking_3 (Masking)            (None, 128, 1)       0           ['input_4[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 128, 128)    512         ['conv1d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " lstm_3 (LSTM)                  (None, 64)           16896       ['masking_3[0][0]']              \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 128, 128)     0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 64)           0           ['lstm_3[0][0]']                 \n",
            "                                                                                                  \n",
            " global_average_pooling1d_3 (Gl  (None, 128)         0           ['activation_11[0][0]']          \n",
            " obalAveragePooling1D)                                                                            \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 192)          0           ['dropout_3[0][0]',              \n",
            "                                                                  'global_average_pooling1d_3[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 3)            579         ['concatenate_3[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 283,203\n",
            "Trainable params: 282,179\n",
            "Non-trainable params: 1,024\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/25\n",
            "1115/1115 - 53s - loss: 0.9795 - accuracy: 0.5600 - val_loss: 4.6643 - val_accuracy: 0.2609 - 53s/epoch - 48ms/step\n",
            "Epoch 2/25\n",
            "1115/1115 - 48s - loss: 0.9690 - accuracy: 0.5606 - val_loss: 2.8855 - val_accuracy: 0.2823 - 48s/epoch - 43ms/step\n",
            "Epoch 3/25\n",
            "1115/1115 - 48s - loss: 0.9633 - accuracy: 0.5613 - val_loss: 5.7851 - val_accuracy: 0.2456 - 48s/epoch - 43ms/step\n",
            "Epoch 4/25\n",
            "1115/1115 - 49s - loss: 0.9602 - accuracy: 0.5616 - val_loss: 4.6373 - val_accuracy: 0.2720 - 49s/epoch - 44ms/step\n",
            "Epoch 5/25\n",
            "1115/1115 - 48s - loss: 0.9574 - accuracy: 0.5622 - val_loss: 8.2234 - val_accuracy: 0.2700 - 48s/epoch - 43ms/step\n",
            "Epoch 6/25\n",
            "1115/1115 - 48s - loss: 0.9549 - accuracy: 0.5630 - val_loss: 13.3205 - val_accuracy: 0.2615 - 48s/epoch - 43ms/step\n",
            "Epoch 7/25\n",
            "1115/1115 - 48s - loss: 0.9524 - accuracy: 0.5635 - val_loss: 19.7092 - val_accuracy: 0.2641 - 48s/epoch - 43ms/step\n",
            "Epoch 8/25\n",
            "1115/1115 - 48s - loss: 0.9496 - accuracy: 0.5645 - val_loss: 13.9522 - val_accuracy: 0.2827 - 48s/epoch - 43ms/step\n",
            "Epoch 9/25\n",
            "1115/1115 - 48s - loss: 0.9472 - accuracy: 0.5654 - val_loss: 19.4507 - val_accuracy: 0.2794 - 48s/epoch - 43ms/step\n",
            "Epoch 10/25\n",
            "1115/1115 - 48s - loss: 0.9452 - accuracy: 0.5663 - val_loss: 24.2566 - val_accuracy: 0.2793 - 48s/epoch - 43ms/step\n",
            "Epoch 11/25\n",
            "1115/1115 - 48s - loss: 0.9436 - accuracy: 0.5669 - val_loss: 31.4444 - val_accuracy: 0.2724 - 48s/epoch - 43ms/step\n",
            "Epoch 12/25\n",
            "1115/1115 - 48s - loss: 0.9419 - accuracy: 0.5671 - val_loss: 33.5458 - val_accuracy: 0.2765 - 48s/epoch - 43ms/step\n",
            "Epoch 13/25\n",
            "1115/1115 - 49s - loss: 0.9406 - accuracy: 0.5675 - val_loss: 34.8191 - val_accuracy: 0.2823 - 49s/epoch - 44ms/step\n",
            "Epoch 14/25\n",
            "1115/1115 - 48s - loss: 0.9391 - accuracy: 0.5681 - val_loss: 43.2193 - val_accuracy: 0.2724 - 48s/epoch - 43ms/step\n",
            "Epoch 15/25\n",
            "1115/1115 - 48s - loss: 0.9377 - accuracy: 0.5685 - val_loss: 28.3450 - val_accuracy: 0.3350 - 48s/epoch - 43ms/step\n",
            "Epoch 16/25\n",
            "1115/1115 - 48s - loss: 0.9363 - accuracy: 0.5693 - val_loss: 33.3352 - val_accuracy: 0.3153 - 48s/epoch - 43ms/step\n",
            "Epoch 17/25\n",
            "1115/1115 - 48s - loss: 0.9349 - accuracy: 0.5696 - val_loss: 32.0076 - val_accuracy: 0.3236 - 48s/epoch - 43ms/step\n",
            "Epoch 18/25\n",
            "1115/1115 - 48s - loss: 0.9334 - accuracy: 0.5703 - val_loss: 28.6075 - val_accuracy: 0.3456 - 48s/epoch - 43ms/step\n",
            "Epoch 19/25\n",
            "1115/1115 - 49s - loss: 0.9322 - accuracy: 0.5706 - val_loss: 27.1468 - val_accuracy: 0.3408 - 49s/epoch - 44ms/step\n",
            "Epoch 20/25\n",
            "1115/1115 - 49s - loss: 0.9307 - accuracy: 0.5714 - val_loss: 27.1307 - val_accuracy: 0.3408 - 49s/epoch - 44ms/step\n",
            "Epoch 21/25\n",
            "1115/1115 - 49s - loss: 0.9292 - accuracy: 0.5721 - val_loss: 28.8080 - val_accuracy: 0.3357 - 49s/epoch - 44ms/step\n",
            "Epoch 22/25\n",
            "1115/1115 - 48s - loss: 0.9279 - accuracy: 0.5730 - val_loss: 30.7099 - val_accuracy: 0.3241 - 48s/epoch - 43ms/step\n",
            "Epoch 23/25\n",
            "1115/1115 - 48s - loss: 0.9264 - accuracy: 0.5737 - val_loss: 34.2542 - val_accuracy: 0.3082 - 48s/epoch - 43ms/step\n",
            "Epoch 24/25\n",
            "1115/1115 - 48s - loss: 0.9253 - accuracy: 0.5743 - val_loss: 34.5745 - val_accuracy: 0.3008 - 48s/epoch - 43ms/step\n",
            "Epoch 25/25\n",
            "1115/1115 - 48s - loss: 0.9238 - accuracy: 0.5751 - val_loss: 44.0091 - val_accuracy: 0.2698 - 48s/epoch - 43ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CCE: 36.88494110107422 Accuracy: 0.314645379781723\n"
          ]
        }
      ],
      "source": [
        "# Return loss value and metric value\n",
        "score = model.evaluate_generator(test_generator, verbose=0)   \n",
        "print(\"CCE: {cce} Accuracy: {acc}\".format(cce=score[0], acc=score[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(41991, 3)\n(41863, 3)\n      0    1    2\n0   1.0  0.0  0.0\n1   1.0  0.0  0.0\n2   1.0  0.0  0.0\n3   1.0  0.0  0.0\n4   1.0  0.0  0.0\n5   1.0  0.0  0.0\n6   1.0  0.0  0.0\n7   1.0  0.0  0.0\n8   1.0  0.0  0.0\n9   0.0  1.0  0.0\n10  0.0  1.0  0.0\n11  0.0  1.0  0.0\n12  1.0  0.0  0.0\n13  0.0  0.0  1.0\n14  0.0  0.0  1.0\n15  0.0  0.0  1.0\n16  1.0  0.0  0.0\n17  1.0  0.0  0.0\n18  1.0  0.0  0.0\n19  1.0  0.0  0.0\n               0             1    2\n0   7.285609e-11  4.930504e-20  1.0\n1   7.142417e-11  4.623306e-20  1.0\n2   6.850139e-11  4.271849e-20  1.0\n3   6.439358e-11  3.788259e-20  1.0\n4   6.105412e-11  3.406776e-20  1.0\n5   5.926413e-11  3.055026e-20  1.0\n6   5.837638e-11  2.741288e-20  1.0\n7   5.781094e-11  2.484647e-20  1.0\n8   5.709624e-11  2.341057e-20  1.0\n9   5.480858e-11  2.062078e-20  1.0\n10  5.048635e-11  1.686181e-20  1.0\n11  4.639060e-11  1.399045e-20  1.0\n12  4.329815e-11  1.166612e-20  1.0\n13  4.205936e-11  1.028923e-20  1.0\n14  4.212455e-11  9.462946e-21  1.0\n15  4.362334e-11  9.542479e-21  1.0\n16  4.521020e-11  9.701408e-21  1.0\n17  4.640122e-11  9.669338e-21  1.0\n18  4.599807e-11  8.914882e-21  1.0\n19  4.410727e-11  7.909907e-21  1.0\n"
          ]
        }
      ],
      "source": [
        "predictions_array = model.predict(test_generator, callbacks=tensorboard_callback)\n",
        "pred_df = pd.DataFrame(predictions_array ) #columns=names\n",
        "pred_labels = pd.DataFrame(testY)\n",
        "# pred_labels = pred.truncate(after=(pred_df.shape[0] - 1))\n",
        "print(pred_labels.shape)\n",
        "print(pred_df.shape)\n",
        "print(pred_labels.head(20))\n",
        "print(pred_df.head(20))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "a = pred_df.tail(100)\n",
        "b = real_returns_df.tail(100)\n",
        "i = 1\n",
        "plt.figure(figsize=(20, 30))\n",
        "for name in names:\n",
        "    plt.subplot(len(names), 1, i)\n",
        "    plt.plot(a[name], color='red')\n",
        "    plt.plot(b[name], color='green')\n",
        "    plt.title(name, y=0.5, loc='right')\n",
        "    i += 1\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%tensorboard --logdir ./logs/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ]
}