{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MultivariateLSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python39764bittfcondad42380e37f19495997ad366e61cbaf70",
      "display_name": "Python 3.9.7 64-bit ('tf': conda)"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.7-final"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# !pip install tensorflow-gpu # make sure cuda toolkit and nvidia dependencies/drivers are correctly installed\n",
        "# !pip install pandas\n",
        "# !pip install numpy\n",
        "# !pip install matplotlib\n",
        "# !pip install mlflow\n",
        "# !pip install scipy\n",
        "# !pip install keras"
      ],
      "metadata": {
        "id": "INLDzE7ASC3Q"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Sf50m6aMRR81"
      },
      "outputs": [],
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.models import Model\n",
        "\n",
        "\n",
        "from keras.layers import Input, LSTM, Bidirectional, Dense, Masking, Reshape, Activation, Masking\n",
        "from keras.layers import Conv1D, BatchNormalization, GlobalAveragePooling1D, Permute, Dropout, concatenate\n",
        "\n",
        "from keras.preprocessing.sequence import TimeseriesGenerator\n",
        "from keras.callbacks import TensorBoard, EarlyStopping\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from time import time\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "from ProcessData import get_vol, get_touches, get_labels, get_horizons, load_data, label_series\n",
        "from ModelArchitecture import generate_mlstmfcn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n",
            "2022-03-02 21:44:49.792437: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-03-02 21:44:50.373291: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /device:GPU:0 with 3504 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
          ]
        }
      ],
      "source": [
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_df, names = load_data(\"../Data/\")"
      ],
      "metadata": {
        "id": "WE-vs10WToFk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatetimeIndex(['2020-01-16 00:00:00', '2020-01-16 00:05:00',\n               '2020-01-16 00:10:00', '2020-01-16 00:15:00',\n               '2020-01-16 00:20:00', '2020-01-16 00:25:00',\n               '2020-01-16 00:30:00', '2020-01-16 00:35:00',\n               '2020-01-16 00:40:00', '2020-01-16 00:45:00',\n               ...\n               '2022-01-15 10:05:00', '2022-01-15 10:10:00',\n               '2022-01-15 10:15:00', '2022-01-15 10:20:00',\n               '2022-01-15 10:25:00', '2022-01-15 10:30:00',\n               '2022-01-15 10:35:00', '2022-01-15 10:40:00',\n               '2022-01-15 10:45:00', '2022-01-15 10:50:00'],\n              dtype='datetime64[ns]', name='Timestamp', length=209972, freq=None)\n"
          ]
        }
      ],
      "source": [
        "BTC_SAMPLE = pd.DataFrame(index = dataset_df.index)\n",
        "BTC_SAMPLE[\"Close\"] = dataset_df['BTC_USD-5m']\n",
        "print(BTC_SAMPLE.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "labels = label_series(BTC_SAMPLE.Close)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatetimeIndex(['2020-01-16 01:10:00', '2020-01-16 01:15:00',\n               '2020-01-16 01:20:00', '2020-01-16 01:25:00',\n               '2020-01-16 01:30:00', '2020-01-16 01:35:00',\n               '2020-01-16 01:40:00', '2020-01-16 01:45:00',\n               '2020-01-16 01:50:00', '2020-01-16 01:55:00',\n               ...\n               '2022-01-15 09:50:00', '2022-01-15 09:55:00',\n               '2022-01-15 10:00:00', '2022-01-15 10:05:00',\n               '2022-01-15 10:10:00', '2022-01-15 10:15:00',\n               '2022-01-15 10:20:00', '2022-01-15 10:25:00',\n               '2022-01-15 10:30:00', '2022-01-15 10:35:00'],\n              dtype='datetime64[ns]', name='Timestamp', length=209955, freq=None)\n"
          ]
        }
      ],
      "source": [
        "print(labels.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "labels.to_csv('./Processed/BTClabels.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# labels = pd.read_csv('./Processed/BTClabels.csv')\n",
        "# labels.set_index('Timestamp', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                       Close\nTimestamp                   \n2020-01-16 00:00:00  8845.70\n2020-01-16 00:05:00  8844.44\n2020-01-16 00:10:00  8824.01\n2020-01-16 00:15:00  8812.22\n2020-01-16 00:20:00  8754.02\n(209972, 1)\nPrice Index 0: 2020-01-16 00:00:00 vs. Label Index 0: 2020-01-16 01:10:00\nPrice Index -1: 2022-01-15 10:50:00 vs. Price Index -1: 2022-01-15 10:35:00\n"
          ]
        }
      ],
      "source": [
        "print(BTC_SAMPLE.head(5))\n",
        "print(BTC_SAMPLE.shape)\n",
        "print(\"Price Index 0: {a} vs. Label Index 0: {b}\".format(a=BTC_SAMPLE.index[0], b=labels.index[0]))\n",
        "print(\"Price Index -1: {a} vs. Price Index -1: {b}\".format(a=BTC_SAMPLE.index[-1], b=labels.index[-1]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 0.0    0.566407\n 1.0    0.217828\n-1.0    0.215765\nName: label, dtype: float64\n(209955, 3)\n"
          ]
        }
      ],
      "source": [
        "BTC_SAMPLE = BTC_SAMPLE.truncate(before=pd.Timestamp(labels.index[0]), \\\n",
        "    after=pd.Timestamp(labels.index[-1]))\n",
        "labels = labels.truncate(before=pd.Timestamp(BTC_SAMPLE.index[0]), \\\n",
        "     after=pd.Timestamp(BTC_SAMPLE.index[-1]))\n",
        "\n",
        "np_labels = labels.to_numpy()\n",
        "one_hot_encoded_labels = to_categorical(np_labels, num_classes=3)\n",
        "print(labels.value_counts(normalize=True, dropna=True))\n",
        "print(one_hot_encoded_labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "values = BTC_SAMPLE.Close.to_numpy()\n",
        "if values.ndim == 1:\n",
        "    values = values.reshape(-1, 1)\n",
        "scaler = MinMaxScaler()\n",
        "scaled = scaler.fit_transform(values)\n",
        "X = scaled\n",
        "\n",
        "\n",
        "input_timesteps = 128\n",
        "batch_size = 128\n",
        "\n",
        "# split into train and test sets (Train: 68%, Val: 12%, Test: 20%)\n",
        "trainX, testX, trainY, testY = train_test_split(X, one_hot_encoded_labels, test_size=0.20, random_state=42, shuffle = False)\n",
        "trainX, valX, trainY, valY = train_test_split(trainX, trainY, test_size=0.15, random_state=42, shuffle=False)\n",
        "\n",
        "train_generator = TimeseriesGenerator(trainX, trainY, length=input_timesteps, sampling_rate=1, batch_size=batch_size)\n",
        "val_generator = TimeseriesGenerator(valX, valY, length=input_timesteps, sampling_rate=1, batch_size=batch_size)\n",
        "test_generator = TimeseriesGenerator(testX, testY, length=input_timesteps, sampling_rate=1, batch_size=batch_size)\n",
        "\n",
        "train_sample_X, train_sample_y = train_generator[0]\n",
        "test_sample_X, test_sample_y = test_generator[0]\n",
        "\n",
        "print(\"trainX Shape:\" + str(trainX.shape))\n",
        "print(\"trainY Shape:\" + str(trainY.shape))\n",
        "print(\"Slice of Features from Train Generator:\" + str(train_sample_X.shape))\n",
        "print(\"Slice of Labels from Train Generator:\" + str(train_sample_y.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqzU_NFganNz",
        "outputId": "a73349e2-5222-494f-b4b6-0a4a9aa4747d"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainX Shape:(142769, 1)\ntrainY Shape:(142769, 3)\nSlice of Features from Train Generator:(128, 128, 1)\nSlice of Labels from Train Generator:(128, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0. 1. 0.] [0. 0. 1.] -1.0\n[0. 1. 0.] [0. 0. 1.] -1.0\n[0. 1. 0.] [0. 1. 0.] 1.0\n[1. 0. 0.] [0. 0. 1.] -1.0\n[1. 0. 0.] [0. 1. 0.] 1.0\n[1. 0. 0.] [0. 1. 0.] 1.0\n[1. 0. 0.] [0. 1. 0.] 1.0\n[1. 0. 0.] [0. 0. 1.] -1.0\n[1. 0. 0.] [0. 0. 1.] -1.0\n[1. 0. 0.] [0. 0. 1.] -1.0\n[1. 0. 0.] [0. 1. 0.] 1.0\n[0. 0. 1.] [0. 1. 0.] 1.0\n[0. 0. 1.] [0. 0. 1.] -1.0\n[1. 0. 0.] [0. 0. 1.] -1.0\n[0. 0. 1.] [0. 0. 1.] -1.0\n[1. 0. 0.] [0. 1. 0.] 1.0\n[1. 0. 0.] [1. 0. 0.] 0.0\n[1. 0. 0.] [1. 0. 0.] 0.0\n[1. 0. 0.] [1. 0. 0.] 0.0\n[1. 0. 0.] [0. 0. 1.] -1.0\n[1. 0. 0.] [1. 0. 0.] 0.0\n[1. 0. 0.] [0. 0. 1.] -1.0\n[1. 0. 0.] [0. 0. 1.] -1.0\n[1. 0. 0.] [0. 0. 1.] -1.0\n[1. 0. 0.] [1. 0. 0.] 0.0\n[0. 0. 1.] [1. 0. 0.] 0.0\n[0. 0. 1.] [1. 0. 0.] 0.0\n[1. 0. 0.] [1. 0. 0.] 0.0\n[1. 0. 0.] [1. 0. 0.] 0.0\n[0. 1. 0.] [1. 0. 0.] 0.0\n[1. 0. 0.] [1. 0. 0.] 0.0\n[1. 0. 0.] [1. 0. 0.] 0.0\n[1. 0. 0.] [1. 0. 0.] 0.0\n[1. 0. 0.] [1. 0. 0.] 0.0\n[1. 0. 0.] [0. 1. 0.] 1.0\n[1. 0. 0.] [0. 1. 0.] 1.0\n[1. 0. 0.] [1. 0. 0.] 0.0\n[0. 1. 0.] [1. 0. 0.] 0.0\n[1. 0. 0.] [1. 0. 0.] 0.0\n[1. 0. 0.] [1. 0. 0.] 0.0\n[1. 0. 0.] [1. 0. 0.] 0.0\n[0. 1. 0.] [1. 0. 0.] 0.0\n[1. 0. 0.] [0. 0. 1.] -1.0\n[1. 0. 0.] [1. 0. 0.] 0.0\n[1. 0. 0.] [1. 0. 0.] 0.0\n[1. 0. 0.] [1. 0. 0.] 0.0\n[1. 0. 0.] [1. 0. 0.] 0.0\n[1. 0. 0.] [1. 0. 0.] 0.0\n[1. 0. 0.] [0. 1. 0.] 1.0\n[0. 0. 1.] [0. 1. 0.] 1.0\n"
          ]
        }
      ],
      "source": [
        "for i in range(0, 50):\n",
        "    print(train_sample_y[i], trainY[i], labels[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_mlstmfcn(max_timesteps, max_features, classes, cells=8):\n",
        "    # MLSTM-FCN\n",
        "    # Multivariate Long-Short-Term Memory  \n",
        "    ip = Input(shape=(max_timesteps, max_features))\n",
        "\n",
        "    x = Masking()(ip)\n",
        "    x = LSTM(cells)(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "\n",
        "    # y = Permute((2, 1))(ip)\n",
        "    y = Conv1D(128, 8, padding='same', kernel_initializer='he_uniform')(ip)\n",
        "    y = BatchNormalization()(y)\n",
        "    y = Activation('relu')(y)\n",
        "    # y = squeeze_excite_block(y)\n",
        "\n",
        "    y = Conv1D(256, 5, padding='same', kernel_initializer='he_uniform')(y)\n",
        "    y = BatchNormalization()(y)\n",
        "    y = Activation('relu')(y)\n",
        "    # y = squeeze_excite_block(y)\n",
        "\n",
        "    y = Conv1D(128, 3, padding='same', kernel_initializer='he_uniform')(y)\n",
        "    y = BatchNormalization()(y)\n",
        "    y = Activation('relu')(y)\n",
        "\n",
        "    y = GlobalAveragePooling1D()(y)\n",
        "\n",
        "    x = concatenate([x, y])\n",
        "\n",
        "    out = Dense(classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(ip, out)\n",
        "    model.summary()\n",
        "\n",
        "    # add load model code here to fine-tune\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "units = 128 # Arbituary Number\n",
        "features = trainX.shape[1] # Number of different trading pairs in the dataframe ie. BTC/USD (aka: # of columns)\n",
        "num_epoch = 25\n",
        "learning_rate = 0.00144\n",
        "class_weight = { 0 : 1, 1 : 3, 2: 3}\n",
        "logdir = \"logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = TensorBoard(log_dir=logdir, histogram_freq=1)\n",
        "\n",
        "# input_shape=(train_sample_X[1].shape, train_sample_X[2].shape)\n",
        "model = generate_mlstmfcn(input_timesteps, features, 3, 64)\n",
        "\n",
        "\n",
        "\n",
        "adam = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "# Stop training when a monitored quantity has stopped improving.\n",
        "callbacks = [EarlyStopping(monitor=\"loss\", \\\n",
        "                            min_delta = 0.00001, \\\n",
        "                            patience = 50, mode = 'auto', \\\n",
        "                            restore_best_weights=True), \\\n",
        "                            tensorboard_callback] \n",
        "\n",
        "\n",
        "# Using regression loss function 'Mean Standard Error' and validation metric 'Mean Absolute Error'\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam, weighted_metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# fit network\n",
        "history = model.fit(train_generator, \\\n",
        "                            epochs=num_epoch, \\\n",
        "                            validation_data=val_generator, \\\n",
        "                            callbacks = callbacks, \\\n",
        "                            verbose=2, \\\n",
        "                            shuffle=False, \\\n",
        "                            initial_epoch=0, \\\n",
        "                            class_weight=class_weight\n",
        "                            )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kEJgb3UIiE36",
        "outputId": "1749a0a4-c9ab-487e-c98a-89457ef4c255"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 128, 1)]     0           []                               \n",
            "                                                                                                  \n",
            " conv1d_6 (Conv1D)              (None, 128, 128)     1152        ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 128, 128)    512         ['conv1d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 128, 128)     0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " conv1d_7 (Conv1D)              (None, 128, 256)     164096      ['activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 128, 256)    1024        ['conv1d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 128, 256)     0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " conv1d_8 (Conv1D)              (None, 128, 128)     98432       ['activation_7[0][0]']           \n",
            "                                                                                                  \n",
            " masking_2 (Masking)            (None, 128, 1)       0           ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 128, 128)    512         ['conv1d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)                  (None, 64)           16896       ['masking_2[0][0]']              \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 128, 128)     0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 64)           0           ['lstm_2[0][0]']                 \n",
            "                                                                                                  \n",
            " global_average_pooling1d_2 (Gl  (None, 128)         0           ['activation_8[0][0]']           \n",
            " obalAveragePooling1D)                                                                            \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 192)          0           ['dropout_2[0][0]',              \n",
            "                                                                  'global_average_pooling1d_2[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 3)            579         ['concatenate_2[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 283,203\n",
            "Trainable params: 282,179\n",
            "Non-trainable params: 1,024\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/25\n",
            "1115/1115 - 31s - loss: 2.0340 - accuracy: 0.4025 - val_loss: 6.1613 - val_accuracy: 0.2503 - 31s/epoch - 28ms/step\n",
            "Epoch 2/25\n",
            "1115/1115 - 27s - loss: 2.0119 - accuracy: 0.4228 - val_loss: 10.4173 - val_accuracy: 0.2240 - 27s/epoch - 24ms/step\n",
            "Epoch 3/25\n",
            "1115/1115 - 27s - loss: 2.0016 - accuracy: 0.4316 - val_loss: 12.2182 - val_accuracy: 0.2192 - 27s/epoch - 24ms/step\n",
            "Epoch 4/25\n",
            "1115/1115 - 26s - loss: 1.9950 - accuracy: 0.4369 - val_loss: 11.1042 - val_accuracy: 0.2195 - 26s/epoch - 24ms/step\n",
            "Epoch 5/25\n",
            "1115/1115 - 26s - loss: 1.9887 - accuracy: 0.4411 - val_loss: 14.4689 - val_accuracy: 0.2181 - 26s/epoch - 24ms/step\n",
            "Epoch 6/25\n",
            "1115/1115 - 27s - loss: 1.9827 - accuracy: 0.4436 - val_loss: 13.1020 - val_accuracy: 0.2284 - 27s/epoch - 24ms/step\n",
            "Epoch 7/25\n",
            "1115/1115 - 27s - loss: 1.9775 - accuracy: 0.4476 - val_loss: 21.5594 - val_accuracy: 0.2661 - 27s/epoch - 24ms/step\n",
            "Epoch 8/25\n",
            "1115/1115 - 27s - loss: 1.9720 - accuracy: 0.4512 - val_loss: 29.6394 - val_accuracy: 0.2654 - 27s/epoch - 24ms/step\n",
            "Epoch 9/25\n",
            "1115/1115 - 27s - loss: 1.9669 - accuracy: 0.4555 - val_loss: 39.5201 - val_accuracy: 0.2589 - 27s/epoch - 24ms/step\n",
            "Epoch 10/25\n",
            "1115/1115 - 27s - loss: 1.9631 - accuracy: 0.4570 - val_loss: 38.0023 - val_accuracy: 0.2672 - 27s/epoch - 24ms/step\n",
            "Epoch 11/25\n",
            "1115/1115 - 27s - loss: 1.9586 - accuracy: 0.4605 - val_loss: 44.6965 - val_accuracy: 0.2629 - 27s/epoch - 24ms/step\n",
            "Epoch 12/25\n",
            "1115/1115 - 27s - loss: 1.9554 - accuracy: 0.4624 - val_loss: 40.2144 - val_accuracy: 0.2713 - 27s/epoch - 24ms/step\n",
            "Epoch 13/25\n",
            "1115/1115 - 27s - loss: 1.9518 - accuracy: 0.4651 - val_loss: 43.7825 - val_accuracy: 0.2654 - 27s/epoch - 24ms/step\n",
            "Epoch 14/25\n",
            "1115/1115 - 27s - loss: 1.9483 - accuracy: 0.4667 - val_loss: 44.1847 - val_accuracy: 0.2664 - 27s/epoch - 24ms/step\n",
            "Epoch 15/25\n",
            "1115/1115 - 27s - loss: 1.9450 - accuracy: 0.4694 - val_loss: 47.1056 - val_accuracy: 0.2712 - 27s/epoch - 24ms/step\n",
            "Epoch 16/25\n",
            "1115/1115 - 27s - loss: 1.9410 - accuracy: 0.4717 - val_loss: 52.1932 - val_accuracy: 0.2653 - 27s/epoch - 24ms/step\n",
            "Epoch 17/25\n",
            "1115/1115 - 27s - loss: 1.9376 - accuracy: 0.4732 - val_loss: 51.8178 - val_accuracy: 0.2674 - 27s/epoch - 24ms/step\n",
            "Epoch 18/25\n",
            "1115/1115 - 27s - loss: 1.9345 - accuracy: 0.4748 - val_loss: 54.8535 - val_accuracy: 0.2693 - 27s/epoch - 24ms/step\n",
            "Epoch 19/25\n",
            "1115/1115 - 27s - loss: 1.9309 - accuracy: 0.4767 - val_loss: 54.2400 - val_accuracy: 0.2715 - 27s/epoch - 24ms/step\n",
            "Epoch 20/25\n",
            "1115/1115 - 27s - loss: 1.9283 - accuracy: 0.4774 - val_loss: 54.4723 - val_accuracy: 0.2712 - 27s/epoch - 24ms/step\n",
            "Epoch 21/25\n",
            "1115/1115 - 27s - loss: 1.9248 - accuracy: 0.4797 - val_loss: 50.4907 - val_accuracy: 0.2718 - 27s/epoch - 24ms/step\n",
            "Epoch 22/25\n",
            "1115/1115 - 27s - loss: 1.9222 - accuracy: 0.4809 - val_loss: 55.3010 - val_accuracy: 0.2652 - 27s/epoch - 24ms/step\n",
            "Epoch 23/25\n",
            "1115/1115 - 27s - loss: 1.9189 - accuracy: 0.4827 - val_loss: 53.5070 - val_accuracy: 0.2653 - 27s/epoch - 24ms/step\n",
            "Epoch 24/25\n",
            "1115/1115 - 27s - loss: 1.9163 - accuracy: 0.4843 - val_loss: 57.4886 - val_accuracy: 0.2650 - 27s/epoch - 24ms/step\n",
            "Epoch 25/25\n",
            "1115/1115 - 27s - loss: 1.9134 - accuracy: 0.4853 - val_loss: 56.7955 - val_accuracy: 0.2640 - 27s/epoch - 24ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 40.43581771850586, Accuracy: 0.3243914544582367\n"
          ]
        }
      ],
      "source": [
        "# Return loss value and metric value\n",
        "score = model.evaluate_generator(test_generator, verbose=0)   \n",
        "print(\"Loss: {cce}, Accuracy: {acc}\".format(cce=score[0], acc=score[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(41863, 3)\n[[1. 0. 0.]\n [1. 0. 0.]\n [1. 0. 0.]\n [1. 0. 0.]\n [1. 0. 0.]\n [1. 0. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [1. 0. 0.]\n [1. 0. 0.]\n [0. 0. 1.]\n [0. 0. 1.]\n [0. 0. 1.]\n [1. 0. 0.]]\n           0             1         2\n0   0.001439  2.005033e-10  0.998561\n1   0.001406  2.006400e-10  0.998594\n2   0.001363  1.992467e-10  0.998637\n3   0.001303  1.915550e-10  0.998697\n4   0.001269  1.905695e-10  0.998731\n5   0.001241  1.877306e-10  0.998759\n6   0.001204  1.810924e-10  0.998796\n7   0.001156  1.737551e-10  0.998844\n8   0.001113  1.720752e-10  0.998887\n9   0.001047  1.615857e-10  0.998953\n10  0.000947  1.427654e-10  0.999053\n11  0.000880  1.309590e-10  0.999120\n12  0.000829  1.196413e-10  0.999171\n13  0.000811  1.142070e-10  0.999189\n14  0.000810  1.129523e-10  0.999190\n"
          ]
        }
      ],
      "source": [
        "predictions_array = model.predict(test_generator, callbacks=tensorboard_callback)\n",
        "pred_df = pd.DataFrame(predictions_array ) #columns=names\n",
        "print(pred_df.shape)\n",
        "print(test_sample_y[0:15])\n",
        "print(pred_df.head(15))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "a = pred_df.tail(100)\n",
        "b = real_returns_df.tail(100)\n",
        "i = 1\n",
        "plt.figure(figsize=(20, 30))\n",
        "for name in names:\n",
        "    plt.subplot(len(names), 1, i)\n",
        "    plt.plot(a[name], color='red')\n",
        "    plt.plot(b[name], color='green')\n",
        "    plt.title(name, y=0.5, loc='right')\n",
        "    i += 1\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%tensorboard --logdir ./logs/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ]
}