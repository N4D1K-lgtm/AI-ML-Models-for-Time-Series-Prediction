{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MultivariateLSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python39764bittfcondad42380e37f19495997ad366e61cbaf70",
      "display_name": "Python 3.9.7 64-bit ('tf': conda)"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.7-final"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# !pip install tensorflow-gpu # make sure cuda toolkit and nvidia dependencies/drivers are correctly installed\n",
        "# !pip install pandas\n",
        "# !pip install numpy\n",
        "# !pip install matplotlib\n",
        "# !pip install mlflow\n",
        "# !pip install scipy\n",
        "# !pip install keras"
      ],
      "metadata": {
        "id": "INLDzE7ASC3Q"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Sf50m6aMRR81"
      },
      "outputs": [],
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.models import Model\n",
        "\n",
        "\n",
        "from keras.layers import Input, LSTM, Bidirectional, Dense, Masking, Reshape, Activation, Masking\n",
        "from keras.layers import Conv1D, BatchNormalization, GlobalAveragePooling1D, Permute, Dropout, concatenate\n",
        "\n",
        "from keras.preprocessing.sequence import TimeseriesGenerator\n",
        "from keras.callbacks import TensorBoard, EarlyStopping\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from time import time\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "from ProcessData import get_vol, get_touches, get_labels, get_horizons, load_data, label_series\n",
        "from ModelArchitecture import generate_mlstmfcn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n",
            "2022-03-02 16:58:34.442379: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-03-02 16:58:34.840507: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /device:GPU:0 with 4177 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
          ]
        }
      ],
      "source": [
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_df, names = load_data(\"../Data/\")"
      ],
      "metadata": {
        "id": "WE-vs10WToFk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatetimeIndex(['2020-01-16 00:00:00', '2020-01-16 00:05:00',\n               '2020-01-16 00:10:00', '2020-01-16 00:15:00',\n               '2020-01-16 00:20:00', '2020-01-16 00:25:00',\n               '2020-01-16 00:30:00', '2020-01-16 00:35:00',\n               '2020-01-16 00:40:00', '2020-01-16 00:45:00',\n               ...\n               '2022-01-15 10:05:00', '2022-01-15 10:10:00',\n               '2022-01-15 10:15:00', '2022-01-15 10:20:00',\n               '2022-01-15 10:25:00', '2022-01-15 10:30:00',\n               '2022-01-15 10:35:00', '2022-01-15 10:40:00',\n               '2022-01-15 10:45:00', '2022-01-15 10:50:00'],\n              dtype='datetime64[ns]', name='Timestamp', length=209972, freq=None)\n"
          ]
        }
      ],
      "source": [
        "BTC_SAMPLE = pd.DataFrame(index = dataset_df.index)\n",
        "BTC_SAMPLE[\"Close\"] = dataset_df['BTC_USD-5m']\n",
        "print(BTC_SAMPLE.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "labels = label_series(BTC_SAMPLE.Close)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatetimeIndex(['2020-01-16 01:10:00', '2020-01-16 01:15:00',\n               '2020-01-16 01:20:00', '2020-01-16 01:25:00',\n               '2020-01-16 01:30:00', '2020-01-16 01:35:00',\n               '2020-01-16 01:40:00', '2020-01-16 01:45:00',\n               '2020-01-16 01:50:00', '2020-01-16 01:55:00',\n               ...\n               '2022-01-15 09:50:00', '2022-01-15 09:55:00',\n               '2022-01-15 10:00:00', '2022-01-15 10:05:00',\n               '2022-01-15 10:10:00', '2022-01-15 10:15:00',\n               '2022-01-15 10:20:00', '2022-01-15 10:25:00',\n               '2022-01-15 10:30:00', '2022-01-15 10:35:00'],\n              dtype='datetime64[ns]', name='Timestamp', length=209955, freq=None)\n"
          ]
        }
      ],
      "source": [
        "print(labels.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "labels.to_csv('./Processed/BTClabels.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# labels = pd.read_csv('./Processed/BTClabels.csv')\n",
        "# labels.set_index('Timestamp', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                       Close\nTimestamp                   \n2020-01-16 00:00:00  8845.70\n2020-01-16 00:05:00  8844.44\n2020-01-16 00:10:00  8824.01\n2020-01-16 00:15:00  8812.22\n2020-01-16 00:20:00  8754.02\n(209972, 1)\nPrice Index 0: 2020-01-16 00:00:00 vs. Label Index 0: 2020-01-16 01:10:00\nPrice Index -1: 2022-01-15 10:50:00 vs. Price Index -1: 2022-01-15 10:35:00\n"
          ]
        }
      ],
      "source": [
        "print(BTC_SAMPLE.head(5))\n",
        "print(BTC_SAMPLE.shape)\n",
        "print(\"Price Index 0: {a} vs. Label Index 0: {b}\".format(a=BTC_SAMPLE.index[0], b=labels.index[0]))\n",
        "print(\"Price Index -1: {a} vs. Price Index -1: {b}\".format(a=BTC_SAMPLE.index[-1], b=labels.index[-1]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 0.0    0.566407\n 1.0    0.217828\n-1.0    0.215765\nName: label, dtype: float64\n(209955, 3)\n"
          ]
        }
      ],
      "source": [
        "BTC_SAMPLE = BTC_SAMPLE.truncate(before=pd.Timestamp(labels.index[0]), \\\n",
        "    after=pd.Timestamp(labels.index[-1]))\n",
        "labels = labels.truncate(before=pd.Timestamp(BTC_SAMPLE.index[0]), \\\n",
        "     after=pd.Timestamp(BTC_SAMPLE.index[-1]))\n",
        "\n",
        "np_labels = labels.to_numpy()\n",
        "one_hot_encoded_labels = to_categorical(np_labels, num_classes=3)\n",
        "print(labels.value_counts(normalize=True, dropna=True))\n",
        "print(one_hot_encoded_labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "values = BTC_SAMPLE.Close.to_numpy()\n",
        "print(values.shape)\n",
        "if values.ndim == 1:\n",
        "    values = values.reshape(-1, 1)\n",
        "scaler = MinMaxScaler()\n",
        "scaled = scaler.fit_transform(values)\n",
        "X = scaled\n",
        "\n",
        "\n",
        "input_timesteps = 128\n",
        "batch_size = 128\n",
        "\n",
        "# split into train and test sets (Train: 68%, Val: 12%, Test: 20%)\n",
        "trainX, testX, trainY, testY = train_test_split(X, one_hot_encoded_labels, test_size=0.20, random_state=42, shuffle = False)\n",
        "trainX, valX, trainY, valY = train_test_split(trainX, trainY, test_size=0.15, random_state=42, shuffle=False)\n",
        "\n",
        "train_generator = TimeseriesGenerator(trainX, trainY, length=input_timesteps, sampling_rate=1, batch_size=batch_size)\n",
        "val_generator = TimeseriesGenerator(valX, valY, length=input_timesteps, sampling_rate=1, batch_size=batch_size)\n",
        "test_generator = TimeseriesGenerator(testX, testY, length=input_timesteps, sampling_rate=1, batch_size=batch_size)\n",
        "\n",
        "train_sample_X, train_sample_y = train_generator[25]\n",
        "\n",
        "print(\"trainX Shape:\" + str(trainX.shape))\n",
        "print(\"trainY Shape:\" + str(trainY.shape))\n",
        "print(\"Slice of Features from Train Generator:\" + str(train_sample_X.shape))\n",
        "print(\"Slice of Labels from Train Generator:\" + str(train_sample_y.shape))\n",
        "print(train_sample_X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqzU_NFganNz",
        "outputId": "a73349e2-5222-494f-b4b6-0a4a9aa4747d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(209955,)\ntrainX Shape:(142769, 1)\ntrainY Shape:(142769, 3)\nSlice of Features from Train Generator:(128, 128, 1)\nSlice of Labels from Train Generator:(128, 3)\n[[[0.07186218]\n  [0.07181924]\n  [0.07180148]\n  ...\n  [0.07301758]\n  [0.07287657]\n  [0.07296939]]\n\n [[0.07181924]\n  [0.07180148]\n  [0.07186326]\n  ...\n  [0.07287657]\n  [0.07296939]\n  [0.07295765]]\n\n [[0.07180148]\n  [0.07186326]\n  [0.07194913]\n  ...\n  [0.07296939]\n  [0.07295765]\n  [0.07269695]]\n\n ...\n\n [[0.07301758]\n  [0.07287657]\n  [0.07296939]\n  ...\n  [0.07786005]\n  [0.07774236]\n  [0.07790206]]\n\n [[0.07287657]\n  [0.07296939]\n  [0.07295765]\n  ...\n  [0.07774236]\n  [0.07790206]\n  [0.07791905]]\n\n [[0.07296939]\n  [0.07295765]\n  [0.07269695]\n  ...\n  [0.07790206]\n  [0.07791905]\n  [0.07898055]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_mlstmfcn(max_timesteps, max_features, classes, cells=8):\n",
        "    # MLSTM-FCN\n",
        "    # Multivariate Long-Short-Term Memory  \n",
        "    ip = Input(shape=(max_timesteps, max_features))\n",
        "\n",
        "    x = Masking()(ip)\n",
        "    x = LSTM(cells)(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "\n",
        "    # y = Permute((2, 1))(ip)\n",
        "    y = Conv1D(128, 8, padding='same', kernel_initializer='he_uniform')(ip)\n",
        "    y = BatchNormalization()(y)\n",
        "    y = Activation('relu')(y)\n",
        "    # y = squeeze_excite_block(y)\n",
        "\n",
        "    y = Conv1D(256, 5, padding='same', kernel_initializer='he_uniform')(y)\n",
        "    y = BatchNormalization()(y)\n",
        "    y = Activation('relu')(y)\n",
        "    # y = squeeze_excite_block(y)\n",
        "\n",
        "    y = Conv1D(128, 3, padding='same', kernel_initializer='he_uniform')(y)\n",
        "    y = BatchNormalization()(y)\n",
        "    y = Activation('relu')(y)\n",
        "\n",
        "    y = GlobalAveragePooling1D()(y)\n",
        "\n",
        "    x = concatenate([x, y])\n",
        "\n",
        "    out = Dense(classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(ip, out)\n",
        "    model.summary()\n",
        "\n",
        "    # add load model code here to fine-tune\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "units = 128 # Arbituary Number\n",
        "features = trainX.shape[1] # Number of different trading pairs in the dataframe ie. BTC/USD (aka: # of columns)\n",
        "num_epoch = 25\n",
        "learning_rate = 0.00144\n",
        "\n",
        "logdir = \"logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = TensorBoard(log_dir=logdir, histogram_freq=1)\n",
        "\n",
        "# input_shape=(train_sample_X[1].shape, train_sample_X[2].shape)\n",
        "model = generate_mlstmfcn(input_timesteps, features, 3, 64)\n",
        "\n",
        "\n",
        "\n",
        "adam = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "# Stop training when a monitored quantity has stopped improving.\n",
        "callbacks = [EarlyStopping(monitor=\"loss\", \\\n",
        "                            min_delta = 0.00001, \\\n",
        "                            patience = 50, mode = 'auto', \\\n",
        "                            restore_best_weights=True), \\\n",
        "                            tensorboard_callback] \n",
        "\n",
        "# Using regression loss function 'Mean Standard Error' and validation metric 'Mean Absolute Error'\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# fit network\n",
        "history = model.fit(train_generator, \\\n",
        "                            epochs=num_epoch, \\\n",
        "                            validation_data=val_generator, \\\n",
        "                            callbacks = callbacks, \\\n",
        "                            verbose=2, \\\n",
        "                            shuffle=False, \\\n",
        "                            initial_epoch=0)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kEJgb3UIiE36",
        "outputId": "1749a0a4-c9ab-487e-c98a-89457ef4c255"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 50, 1)]      0           []                               \n",
            "                                                                                                  \n",
            " conv1d_6 (Conv1D)              (None, 50, 128)      1152        ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 50, 128)     512         ['conv1d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 50, 128)      0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " conv1d_7 (Conv1D)              (None, 50, 256)      164096      ['activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 50, 256)     1024        ['conv1d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 50, 256)      0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " conv1d_8 (Conv1D)              (None, 50, 128)      98432       ['activation_7[0][0]']           \n",
            "                                                                                                  \n",
            " masking_2 (Masking)            (None, 50, 1)        0           ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 50, 128)     512         ['conv1d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)                  (None, 64)           16896       ['masking_2[0][0]']              \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 50, 128)      0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 64)           0           ['lstm_2[0][0]']                 \n",
            "                                                                                                  \n",
            " global_average_pooling1d_2 (Gl  (None, 128)         0           ['activation_8[0][0]']           \n",
            " obalAveragePooling1D)                                                                            \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 192)          0           ['dropout_2[0][0]',              \n",
            "                                                                  'global_average_pooling1d_2[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 3)            579         ['concatenate_2[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 283,203\n",
            "Trainable params: 282,179\n",
            "Non-trainable params: 1,024\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/25\n",
            "4460/4460 - 39s - loss: 0.9568 - accuracy: 0.5655 - val_loss: 27.4906 - val_accuracy: 0.2330 - 39s/epoch - 9ms/step\n",
            "Epoch 2/25\n",
            "4460/4460 - 31s - loss: 0.9270 - accuracy: 0.5743 - val_loss: 35.6000 - val_accuracy: 0.2429 - 31s/epoch - 7ms/step\n",
            "Epoch 3/25\n",
            "4460/4460 - 44s - loss: 0.9128 - accuracy: 0.5808 - val_loss: 36.4614 - val_accuracy: 0.2395 - 44s/epoch - 10ms/step\n",
            "Epoch 4/25\n",
            "4460/4460 - 55s - loss: 0.9020 - accuracy: 0.5855 - val_loss: 25.3038 - val_accuracy: 0.2360 - 55s/epoch - 12ms/step\n",
            "Epoch 5/25\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_170008/3999224957.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# fit network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m history = model.fit(train_generator, \\\n\u001b[0m\u001b[1;32m     29\u001b[0m                             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2954\u001b[0m       (graph_function,\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2956\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1854\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CCE: 314.1697082519531 Accuracy: 0.3453422784805298\n"
          ]
        }
      ],
      "source": [
        "# Return loss value and metric value\n",
        "score = model.evaluate_generator(test_generator, verbose=0)   \n",
        "print(\"CCE: {cce} Accuracy: {acc}\".format(cce=score[0], acc=score[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(41941, 3)\n(41941, 3)\n             0       1       2\n0  68747.96875  4000.0  4000.0\n1  68747.96875  4000.0  4000.0\n2  68747.96875  4000.0  4000.0\n3  68747.96875  4000.0  4000.0\n4  68747.96875  4000.0  4000.0\n          0    1         2\n0  0.000011  0.0  0.999989\n1  0.000009  0.0  0.999990\n2  0.000009  0.0  0.999991\n3  0.000011  0.0  0.999989\n4  0.000012  0.0  0.999988\n"
          ]
        }
      ],
      "source": [
        "predictions_array = model.predict(test_generator, callbacks=tensorboard_callback)\n",
        "pred_df = pd.DataFrame(predictions_array ) #columns=names\n",
        "real_returns_df = pd.DataFrame(real_returns_array) #columns=names\n",
        "real_returns_df = real_returns_df.truncate(after=(pred_df.shape[0] - 1))\n",
        "print(pred_df.shape)\n",
        "print(real_returns_df.shape)\n",
        "print(real_returns_df.head(5))\n",
        "print(pred_df.head(5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "a = pred_df.tail(100)\n",
        "b = real_returns_df.tail(100)\n",
        "i = 1\n",
        "plt.figure(figsize=(20, 30))\n",
        "for name in names:\n",
        "    plt.subplot(len(names), 1, i)\n",
        "    plt.plot(a[name], color='red')\n",
        "    plt.plot(b[name], color='green')\n",
        "    plt.title(name, y=0.5, loc='right')\n",
        "    i += 1\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%tensorboard --logdir ./logs/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ]
}